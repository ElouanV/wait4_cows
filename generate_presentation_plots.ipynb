{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688be557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 13\n",
    "plt.rcParams['figure.titlesize'] = 14\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('presentation_plots_final')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"âœ… Setup complete\")\n",
    "print(f\"ðŸ“ Output directory: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd01624",
   "metadata": {},
   "source": [
    "## 1. Next Cow Prediction - Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179fab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all next cow prediction experiments\n",
    "experiments = {\n",
    "    'Pure MLP': 'pure_mlp_next_cow_output',\n",
    "    'MLP + Logic': 'mlp_next_cow_output',\n",
    "    'Logic Only': 'logic_only_onehot_lr01_3000ep',\n",
    "    'One-Hot MLP': 'onehot_mlp_output',\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, path in experiments.items():\n",
    "    exp_path = Path(path)\n",
    "    if exp_path.exists():\n",
    "        try:\n",
    "            with open(exp_path / 'config.json', 'r') as f:\n",
    "                config = json.load(f)\n",
    "            \n",
    "            history_file = exp_path / 'history.json'\n",
    "            if history_file.exists():\n",
    "                with open(history_file, 'r') as f:\n",
    "                    history = json.load(f)\n",
    "                results[name] = {'config': config, 'history': history}\n",
    "                print(f\"âœ“ {name}: {len(history['train_loss'])} epochs\")\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— {name}: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… Loaded {len(results)} experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a8c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Next Cow Prediction: Training Comparison', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "# Training Loss\n",
    "for idx, (name, data) in enumerate(results.items()):\n",
    "    if 'train_loss' in data['history']:\n",
    "        values = data['history']['train_loss']\n",
    "        if len(values) > 500:\n",
    "            step = len(values) // 500\n",
    "            epochs = list(range(0, len(values), step))\n",
    "            values = values[::step]\n",
    "        else:\n",
    "            epochs = list(range(len(values)))\n",
    "        axes[0, 0].plot(epochs, values, label=name, linewidth=2, color=colors[idx % len(colors)], alpha=0.9)\n",
    "\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Loss', fontsize=11)\n",
    "axes[0, 0].set_title('Training Loss', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=10, framealpha=0.9)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation Loss\n",
    "for idx, (name, data) in enumerate(results.items()):\n",
    "    if 'val_loss' in data['history']:\n",
    "        values = data['history']['val_loss']\n",
    "        if len(values) > 500:\n",
    "            step = len(values) // 500\n",
    "            epochs = list(range(0, len(values), step))\n",
    "            values = values[::step]\n",
    "        else:\n",
    "            epochs = list(range(len(values)))\n",
    "        axes[0, 1].plot(epochs, values, label=name, linewidth=2, color=colors[idx % len(colors)], alpha=0.9)\n",
    "\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Loss', fontsize=11)\n",
    "axes[0, 1].set_title('Validation Loss', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=10, framealpha=0.9)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Training Accuracy\n",
    "for idx, (name, data) in enumerate(results.items()):\n",
    "    if 'train_acc' in data['history']:\n",
    "        values = data['history']['train_acc']\n",
    "        if len(values) > 500:\n",
    "            step = len(values) // 500\n",
    "            epochs = list(range(0, len(values), step))\n",
    "            values = values[::step]\n",
    "        else:\n",
    "            epochs = list(range(len(values)))\n",
    "        axes[1, 0].plot(epochs, values, label=name, linewidth=2, color=colors[idx % len(colors)], alpha=0.9)\n",
    "\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Accuracy', fontsize=11)\n",
    "axes[1, 0].set_title('Training Accuracy', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=10, framealpha=0.9)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation Accuracy\n",
    "for idx, (name, data) in enumerate(results.items()):\n",
    "    if 'val_acc' in data['history']:\n",
    "        values = data['history']['val_acc']\n",
    "        if len(values) > 500:\n",
    "            step = len(values) // 500\n",
    "            epochs = list(range(0, len(values), step))\n",
    "            values = values[::step]\n",
    "        else:\n",
    "            epochs = list(range(len(values)))\n",
    "        axes[1, 1].plot(epochs, values, label=name, linewidth=2, color=colors[idx % len(colors)], alpha=0.9)\n",
    "\n",
    "axes[1, 1].set_xlabel('Epoch', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Accuracy', fontsize=11)\n",
    "axes[1, 1].set_title('Validation Accuracy', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=10, framealpha=0.9)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / '01_next_cow_training_curves.png', bbox_inches='tight', dpi=300)\n",
    "plt.savefig(output_dir / '01_next_cow_training_curves.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Saved: 01_next_cow_training_curves.png/.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16fd0f9",
   "metadata": {},
   "source": [
    "## 2. Performance Comparison Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74444414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract final metrics\n",
    "performance_data = []\n",
    "for name, data in results.items():\n",
    "    if data['history']:\n",
    "        best_val_acc = max(data['history']['val_acc']) if 'val_acc' in data['history'] else 0\n",
    "        final_train_acc = data['history']['train_acc'][-1] if 'train_acc' in data['history'] else 0\n",
    "        \n",
    "        performance_data.append({\n",
    "            'Model': name,\n",
    "            'Validation': best_val_acc * 100,\n",
    "            'Training': final_train_acc * 100\n",
    "        })\n",
    "\n",
    "df_perf = pd.DataFrame(performance_data)\n",
    "\n",
    "# Create grouped bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(df_perf))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, df_perf['Training'], width, label='Training Accuracy', \n",
    "               color='#2ca02c', alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "bars2 = ax.bar(x + width/2, df_perf['Validation'], width, label='Validation Accuracy', \n",
    "               color='#1f77b4', alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Next Cow Prediction: Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_perf['Model'], fontsize=11)\n",
    "ax.legend(fontsize=11, loc='upper right', framealpha=0.9)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim(0, max(df_perf['Training'].max(), df_perf['Validation'].max()) * 1.15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / '02_performance_comparison.png', bbox_inches='tight', dpi=300)\n",
    "plt.savefig(output_dir / '02_performance_comparison.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save table\n",
    "df_perf.to_csv(output_dir / '02_performance_comparison.csv', index=False)\n",
    "print(\"\\nðŸ“Š Performance Summary:\")\n",
    "print(df_perf.to_string(index=False))\n",
    "print(\"\\nâœ… Saved: 02_performance_comparison.png/.pdf/.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d431bd",
   "metadata": {},
   "source": [
    "## 3. Model Architecture Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40698193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model details\n",
    "model_info = []\n",
    "for name, data in results.items():\n",
    "    config = data['config']\n",
    "    model_info.append({\n",
    "        'Model': name,\n",
    "        'Epochs': config.get('epochs', 'N/A'),\n",
    "        'Batch Size': config.get('batch_size', 'N/A'),\n",
    "        'Learning Rate': config.get('learning_rate', 'N/A'),\n",
    "        'Architecture': 'Logic Only' if config.get('skip_mlp') else ('MLP+Logic' if config.get('use_logic_layer') else 'Pure MLP')\n",
    "    })\n",
    "\n",
    "df_info = pd.DataFrame(model_info)\n",
    "df_info.to_csv(output_dir / '03_model_configurations.csv', index=False)\n",
    "print(\"ðŸ“‹ Model Configurations:\")\n",
    "print(df_info.to_string(index=False))\n",
    "print(\"\\nâœ… Saved: 03_model_configurations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d76118",
   "metadata": {},
   "source": [
    "## 4. Temporal Graph Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporal experiment data\n",
    "experiments_temporal = {\n",
    "    'Brush': 'brush_experiment',\n",
    "    'Water Spot': 'water_spot_experiment', \n",
    "    'Lactation': 'lactation_experiment'\n",
    "}\n",
    "\n",
    "temporal_data = {}\n",
    "for name, exp_dir in experiments_temporal.items():\n",
    "    exp_path = Path(exp_dir)\n",
    "    if exp_path.exists():\n",
    "        summary_files = list(exp_path.glob('*_summary.csv'))\n",
    "        if summary_files:\n",
    "            try:\n",
    "                df = pd.read_csv(summary_files[0])\n",
    "                temporal_data[name] = df\n",
    "                print(f\"âœ“ {name}: {len(df)} time windows\")\n",
    "            except Exception as e:\n",
    "                print(f\"âœ— {name}: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… Loaded {len(temporal_data)} temporal experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe49c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temporal evolution\n",
    "if temporal_data:\n",
    "    fig, axes = plt.subplots(len(temporal_data), 2, figsize=(14, 5*len(temporal_data)))\n",
    "    if len(temporal_data) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    fig.suptitle('Temporal Graph Evolution: POI Experiments', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx, (name, df) in enumerate(temporal_data.items()):\n",
    "        # Plot edges\n",
    "        if 'num_edges' in df.columns:\n",
    "            axes[idx, 0].plot(df['num_edges'], linewidth=2, color='#1f77b4')\n",
    "            axes[idx, 0].fill_between(range(len(df)), df['num_edges'], alpha=0.3, color='#1f77b4')\n",
    "            axes[idx, 0].set_title(f'{name}: Number of Edges Over Time', fontsize=12, fontweight='bold')\n",
    "            axes[idx, 0].set_xlabel('Time Window', fontsize=11)\n",
    "            axes[idx, 0].set_ylabel('Number of Edges', fontsize=11)\n",
    "            axes[idx, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot nodes\n",
    "        if 'num_nodes' in df.columns:\n",
    "            axes[idx, 1].plot(df['num_nodes'], linewidth=2, color='#ff7f0e')\n",
    "            axes[idx, 1].fill_between(range(len(df)), df['num_nodes'], alpha=0.3, color='#ff7f0e')\n",
    "            axes[idx, 1].set_title(f'{name}: Active Nodes Over Time', fontsize=12, fontweight='bold')\n",
    "            axes[idx, 1].set_xlabel('Time Window', fontsize=11)\n",
    "            axes[idx, 1].set_ylabel('Number of Active Nodes', fontsize=11)\n",
    "            axes[idx, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '04_temporal_graph_evolution.png', bbox_inches='tight', dpi=300)\n",
    "    plt.savefig(output_dir / '04_temporal_graph_evolution.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… Saved: 04_temporal_graph_evolution.png/.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6af45",
   "metadata": {},
   "source": [
    "## 5. Copy Existing Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c7e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Copy existing presentation figures\n",
    "source_dirs = ['presentation_figures', 'presentation_results']\n",
    "copied = 0\n",
    "\n",
    "for source_dir in source_dirs:\n",
    "    source_path = Path(source_dir)\n",
    "    if source_path.exists():\n",
    "        for file in source_path.glob('*.*'):\n",
    "            if file.suffix in ['.png', '.pdf', '.csv']:\n",
    "                dest = output_dir / f'existing_{file.name}'\n",
    "                shutil.copy2(file, dest)\n",
    "                copied += 1\n",
    "                print(f\"  Copied: {file.name}\")\n",
    "\n",
    "print(f\"\\nâœ… Copied {copied} existing figures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf777ea",
   "metadata": {},
   "source": [
    "## 6. Generate Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary\n",
    "summary_text = f\"\"\"\n",
    "PRESENTATION PLOTS SUMMARY\n",
    "{'='*80}\n",
    "Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Output Directory: {output_dir.absolute()}\n",
    "\n",
    "EXPERIMENTS ANALYZED:\n",
    "{'-'*80}\n",
    "\"\"\"\n",
    "\n",
    "# Next Cow Prediction\n",
    "summary_text += \"\\n1. NEXT COW PREDICTION\\n\"\n",
    "for name, data in results.items():\n",
    "    if data['history']:\n",
    "        best_val = max(data['history']['val_acc'])\n",
    "        summary_text += f\"   - {name:20s}: {best_val*100:5.2f}% validation accuracy\\n\"\n",
    "\n",
    "# Temporal Experiments\n",
    "summary_text += \"\\n2. TEMPORAL GRAPH EXPERIMENTS\\n\"\n",
    "for name, df in temporal_data.items():\n",
    "    avg_nodes = df['num_nodes'].mean() if 'num_nodes' in df else 0\n",
    "    avg_edges = df['num_edges'].mean() if 'num_edges' in df else 0\n",
    "    summary_text += f\"   - {name:20s}: {avg_nodes:.1f} avg nodes, {avg_edges:.1f} avg edges\\n\"\n",
    "\n",
    "summary_text += f\"\"\"\n",
    "{'-'*80}\n",
    "\n",
    "GENERATED FILES:\n",
    "\"\"\"\n",
    "\n",
    "# List all generated files\n",
    "for file in sorted(output_dir.glob('*')):\n",
    "    size = file.stat().st_size / 1024\n",
    "    summary_text += f\"  - {file.name:50s} ({size:>8.1f} KB)\\n\"\n",
    "\n",
    "summary_text += f\"\"\"\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "# Save summary\n",
    "with open(output_dir / 'README.txt', 'w') as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(summary_text)\n",
    "print(\"\\nâœ… Saved: README.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a72aab",
   "metadata": {},
   "source": [
    "## âœ… All Plots Generated!\n",
    "\n",
    "Check the `presentation_plots_final/` directory for:\n",
    "- Training curves (PNG + PDF)\n",
    "- Performance comparisons (PNG + PDF + CSV)\n",
    "- Temporal graph evolution (PNG + PDF)\n",
    "- Model configurations (CSV)\n",
    "- Existing figures copied\n",
    "- Summary report (README.txt)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
